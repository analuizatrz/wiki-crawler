'''Search engine optimization''' ('''SEO'''), a subset of [[search engine marketing]], is the process of improving the volume and quality of traffic to a [[web site]] from search engines via "natural" ("organic" or "algorithmic") [[Search engine results page|search results]]. SEO can also target specialized searches such as [[image search]], [[local search (Internet)|local search]], and industry-specific [[vertical search]] engines. 

[[Image:serp.jpg|thumb|right|A typical Search Engine Results Page (SERP)]]

SEO is [[marketing]] by understanding how search [[algorithms]] work and what human visitors might search for, to help match those visitors with sites offering what they are interested in finding. Some SEO efforts may involve optimizing a site's coding, presentation, and structure, without making very noticeable changes to human visitors, such as incorporating a clear hierarchical structure to a site, and avoiding or fixing problems that might keep search engine indexing programs from fully [[spidering]] a site. Other, more noticeable efforts, involve including unique content on pages that can be easily indexed and extracted from those pages by search engines while also appealing to human visitors.

The term SEO can also refer to "search engine optimizers," a term adopted by an industry of [[consultants]] who carry out optimization projects on behalf of clients, and by employees of site owners who may perform SEO services in-house. Search engine optimizers often offer SEO as a stand-alone service or as a part of a larger marketing campaign. Because effective SEO can require making changes to the source code of a site, it is often very helpful when incorporated into the initial development and design of a site, leading to the use of the term "Search Engine Friendly" to describe designs, menus, [[content management systems]] and [[Shopping cart software|shopping carts]] that can be optimized easily and effectively.
 
==History==
===Origin: Early search engines===
Webmasters and content providers began optimizing sites for search engines in the mid-1990s, as the first search engines were cataloging the early [[World Wide Web|Web]].
 
Initially, all a [[webmaster]] needed to do was submit a page, or [[Uniform Resource Locator|URL]], to the various engines which would send a [[Web crawler|spider]] to "crawl" that page, extract links to other pages from it, and return information found on the page to be [[Index (search engine)|indexed]].<ref>[http://www.webir.org/resources/phd/pinkerton_2000.pdf Finding What People Want: Experiences with the WebCrawler] The Second International WWW Conference Chicago, USA, October 17-20, 1994, written by Brian Pinkerton</ref> The process involves a search engine spider downloading a page and storing it on the search engine's own server, where a second program, known as an [[search engine indexing|indexer]], extracts various information about the page, such as the words it contains and where these are located, as well as any weight for specific words, as well as any and all links the page contains, which are then placed into a scheduler for crawling at a later date.

Site owners started to recognize the value of having their sites highly ranked and visible in search engine results, creating an opportunity for both "white hat" and "black hat" SEO practitioners. Indeed, by [[1996]], [[email]] [[E-mail spam|spam]] could be found on Usenet touting SEO services.<ref>[http://groups.google.com/group/comp.infosystems.www.authoring.html/browse_thread/thread/19ac595372a23e5f/c243e50885faa2cd?lnk=st&q=&rnum=2#c243e50885faa2cd Example Email] from [[Google Groups]]</ref> The earliest known use of the phrase "search engine optimization" was a spam message posted on [[Usenet]] on July 26, 1997.<ref>[http://groups.google.com/group/alt.current-events.net-abuse.spam/browse_thread/thread/6fee2777dc17b8ab/3858bff94e56aff3?lnk=st&q=%22search+engine+optimization%22&rnum=1#3858bff94e56aff3 Usenet post] mentioning SEO, July 26, 1997</ref>

Early versions of search [[algorithm]]s relied on webmaster-provided information such as the keyword [[meta tag]], or index files in engines like [[Aliweb|ALIWEB]]. Meta-tags provided a guide to each page's content. But indexing pages based upon meta data was found to be less than reliable, because some webmasters abused meta tags by including irrelevant keywords to artificially increase page impressions for their website and to increase their ad revenue. [[Cost Per Mille|Cost per thousand impressions]] was at the time the common means of monetizing content websites. Inaccurate, incomplete, and inconsistent meta data in meta tags caused pages to rank for irrelevant searches, and fail to rank for relevant searches.<ref>[http://www.well.com/~doctorow/metacrap.htm Metacrap: Putting the torch to seven straw-men of the meta-utopia], written by Cory Doctorow, Version 1.3: 26 August 2001</ref> Web content providers also manipulated a number of attributes within the HTML source of a page in an attempt to rank well in search engines.<ref>[http://www.csse.monash.edu.au/~lloyd/tilde/InterNet/Search/1998_WWW7.html What is a tall poppy among web pages?], Proceedings of the seventh conference on World Wide Web, Brisbane, Australia, 1998, written by Pringle, G., Allison, L., and Dowe, D.</ref> 

By relying so much upon factors exclusively within a webmaster's control, early search engines suffered from abuse and ranking manipulation. To provide better results to their users, search engines had to adapt to ensure their [[SERP|results pages]] showed the most relevant search results, rather than unrelated pages stuffed with numerous keywords by unscrupulous webmasters. Search engines responded by developing more complex ranking [[algorithm]]s, taking into account additional factors that were more difficult for webmasters to manipulate.

===Second stage: Link analysis===
[[Larry Page]] and [[Sergei Brin]], while graduate students at [[Stanford University]], developed a search engine called "backrub" that relied on a mathematical [[algorithm]] to rate the prominence of web pages. The number calculated by the algorithm is called [[PageRank]], and is based upon the quantity and prominence of incoming [[hyperlink|links]].<ref name="lgscalehyptxt">Brin, Sergey and Page, Larry, [http://www-db.stanford.edu/~backrub/google.html The Anatomy of a Large-Scale Hypertextual Web Search Engine], Proceedings of the seventh international conference on World Wide Web 7, 1998, Pages: 107-117</ref> PageRank estimates the likelihood that a given page will be reached by a web user who randomly surfs the web, and follows links from one page to another. In effect, this means that some links are stronger than others, as a higher PageRank page is more likely to be reached by the random surfer.

Page and Brin founded Google in [[1998]]. On strong word of mouth from programmers, Google became a popular search engine. Off-page factors such as PageRank and hyperlink analysis were considered, as well as on-page factors, to enable Google to avoid the kind of manipulation seen in search engines focusing primarily upon on-page factors for their rankings. Although PageRank was more difficult to game, webmasters had already developed link building tools and schemes to influence the [[Inktomi]] search engine, and these methods proved similarly applicable to gaining PageRank. Many sites focused on exchanging, buying, and selling links, often on a massive scale. Some of these schemes, or [[link farm]]s, involved the creation of thousands of sites for the sole purpose of link spamming.<ref>Zoltan Gyongyi and Hector Garcia-Molina, [http://infolab.stanford.edu/~zoltan/publications/gyongyi2005link.pdf Link Spam Alliances], Proceedings of the 31st VLDB Conference, Trondheim, Norway, 2005</ref>

===Current technology: Search engines consider many signals===
To reduce the impact of link schemes, search engines have developed a wider range of undisclosed off-site factors they use in their algorithms. As a search engine may use hundreds of factors in ranking the listings on its SERPs, the factors themselves and the weight each carries can change continually, and algorithms can differ widely. The four leading search engines, [[Google]], [[Yahoo]], [[Microsoft]] and [[Ask.com]], do not disclose the algorithms they use to rank pages. Some SEOs have carried out controlled experiments to gauge the effects of different approaches to search optimization, and share results through online forums and blogs.<ref>Danny Sullivan, [http://blog.searchenginewatch.com/blog/050929-072711 Rundown On Search Ranking Factors], [[Search Engine Watch]], Sep. 29, 2005</ref> SEO practitioners may also study patents held by various search engines to gain insight into the algorithms.<ref>Christine Churchill, [http://searchenginewatch.com/showPage.html?page=3564261 Understanding Search Engine Patents], [[Search Engine Watch]], November 23, 2005
</ref>

==Optimizing for traffic quality==

In addition to seeking better rankings, search engine optimization is also concerned with [http://theblogwhichsaysall.blogspot.com/2007/04/five-powerful-strategies-for-getting.html traffic quality]. Traffic quality is measured by how often a visitor using a specific keyword phrase leads to a desired [[conversion rate|conversion action]], such as making a purchase, viewing or downloading a certain page, requesting further information, signing up for a newsletter, or taking some other specific action. 

By improving the quality of a page's search listings, more searchers may select that page, and those searchers may be more likely to convert. Examples of SEO tactics to improve traffic quality include writing attention-grabbing titles, adding accurate [[meta tag|meta descriptions]], and choosing a domain and URL that improve the site's branding.

==Relationship between SEO and search engines==
 
By [[1997]] search engines recognized that some webmasters were making efforts to rank well in their search engines, and even manipulating the page rankings in search results. In some early search engines, such as [[Infoseek]], ranking first was as easy as grabbing the source code of the top-ranked page, placing it on your website, and submitting a URL to instantly index and rank that page.{{Fact|date=March 2007}}

Due to the high value and targeting of search results, there is potential for an adversarial relationship between search engines and SEOs. In 2005, an annual conference named AirWeb<ref name="airweb">[http://airweb.cse.lehigh.edu/ AirWeb] Adversarial Information Retrieval on the Web, annual conference and workshop for researchers and professionals</ref> was created to discuss bridging the gap and minimizing the sometimes damaging effects of aggressive web content providers.

Some more aggressive site owners and SEOs generate automated sites or employ techniques that eventually get domains banned from the search engines. Many search engine optimization companies, which sell services, employ long-term, low-risk strategies, and most SEO firms that do employ high-risk strategies do so on their own affiliate, lead-generation, or content sites, instead of risking client websites.

Some SEO companies employ aggressive techniques that get their client websites banned from the search results. The [[Wall Street Journal]] profiled a company, [[Traffic Power]], that allegedly used high-risk techniques and failed to disclose those risks to its clients.<ref>Startup Journal ([[Wall Street Journal]]), [http://www.startupjournal.com/ecommerce/ecommerce/20050923-kesmodel.html 'Optimize' Rankings At Your Own Risk] by David Kesmodel at The Wall Street Journal Online, September 9 2005</ref> [[Wired Magazine|Wired]] reported the same company sued a blogger for mentioning that they were banned.<ref name="wired09082005">[[Wired Magazine]], [http://www.wired.com/news/culture/0,1284,68799,00.html Legal Showdown in Search Fracas], Sep, 08, 2005, written by Adam L. Penenberg</ref> Google's [[Matt Cutts]] later confirmed that Google did in fact ban Traffic Power and some of its clients.<ref>[[Matt Cutts|Cutts, Matt]], [http://www.mattcutts.com/blog/confirming-a-penalty/ Confirming a penalty], published on 2006-02-02 at [http://www.mattcutts.com/blog/ Matt Cuts Blog]</ref>

Some search engines have also reached out to the SEO industry, and are frequent sponsors and guests at SEO conferences and seminars. In fact, with the advent of paid inclusion, some search engines now have a vested interest in the health of the optimization community. All of the main search engines provide information/guidelines to help with site optimization: Google's, Yahoo!'s, MSN's and Ask.com's. Google has a Sitemaps program<ref name="googlesitemaps">[http://www.google.com/webmasters/sitemaps/login Google Web Master Central], formerly known as Google Sitemaps</ref> to help webmasters learn if Google is having any problems indexing their website and also provides data on Google traffic to the website. Yahoo! has [http://siteexplorer.search.yahoo.com Site Explorer] that provides a way to submit your URLs for free (like MSN/Google), determine how many pages are in the Yahoo! index and drill down on inlinks to deep pages. Yahoo! has an Ambassador Program<ref name="y-ambprg">[http://searchmarketing.yahoo.com/af/amb.php Ambassador Program] by Yahoo! Search Marketing</ref> and Google has a program for qualifying Google Advertising Professionals.<ref name="g-advpro">[[https://adwords.google.com/select/professionalwelcome Google Advertising Professionals]], a Program by Google AdWords, Google's Pay-Per-Click Advertising Service</ref>

===Getting into [http://theblogwhichsaysall.blogspot.com/2007/04/how-to-optimize-yours-blog-for-better.html search engines'] databases===
As of [[2007]] the leading contextual search engines do not require submission. They discover new sites and pages automatically. Google and Yahoo offer submission programs, such as [[Google Webmaster Tools|Google Sitemaps]], for which an XML type feed can be created and submitted. These programs are designed to assist sites that may have pages that aren't discoverable by automatically following links.<ref>[http://www.google.com/support/webmasters/bin/answer.py?answer=40318&topic=8514 What is a Sitemap file and why should I have one?], Google Webmaster Tools, Accessed March 19, 2007</ref>

Search engine crawlers may look at a number of different factors when [[Web crawler|crawling]] a site, and many pages from a site may not be indexed by the search engines until they gain more PageRank, links or traffic. Distance of pages from the root directory of a site may also be a factor in whether or not pages get crawled, as well as other importance metrics. Cho et al.<ref name="cho">[http://dbpubs.stanford.edu:8090/pub/1998-51 Efficient crawling through URL ordering] by Cho, J., Garcia-Molina, H. , 1998, published at "Proceedings of the seventh conference on World Wide Web", Brisbane, Australia</ref> described some standards for those decisions as to which pages are visited and sent by a crawler to be included in a search engine's index.

Some search engines, notably Yahoo!, operate a paid submission service that guarantee crawling for either a set fee or [[Pay per click|cost per click]]. Such programs usually guarantee inclusion in the database, but do not guarantee specific ranking within the search results.

===Preventing search indexing===
{{main|robots.txt}}
To avoid undesirable search listings, webmasters can instruct spiders not to crawl certain files or directories through the standard [[robots.txt]] file in the root directory of the domain. Additionally, a page can be explicitly excluded from a search engine's database by using a [[meta tag]] specific to robots. When a search engine visits a site, the robots.txt located in the [[root directory]] is the first file crawled. The robots.txt file is then parsed, and will instruct the robot as to which pages are not to be crawled. As a search engine crawler may keep a cached copy of this file, it may on occasion crawl pages a webmaster does not wish crawled.

Pages typically prevented from being crawled include login specific pages such as shopping carts and user-specific content such as search results from internal searches.

==Types of SEO==
SEO techniques are classified by some into two broad categories: techniques that search engines recommend as part of good design, and those techniques that search engines do not approve of and attempt to minimize the effect of, referred to as [[spamdexing]]. Professional SEO consultants do not offer spamming and spamdexing techniques amongst the services that they provide to clients. Some industry commentators classify these methods, and the practitioners who utilize them, as either "[[white hat]] SEO", or "[[Blackhatter|black hat]] SEO".<ref>Goodman, Andrew, SearchEngineWatch, [http://searchenginewatch.com/showPage.html?page=3483941 Search Engine Showdown: Black Hats vs. White Hats at SES]</ref> Many SEO consultants reject the black and white hat dichotomy as a convenient but unfortunate and misleading over-simplification that makes the industry look bad as a whole. 

==="White hat" ===

An SEO tactic, technique or method is considered "White hat" if it conforms to the search engines' guidelines and/or involves no deception. As the search engine guidelines<ref name="a-wmguide">{{cite web|url=http://about.ask.com/en/docs/about/editorial_guidelines.shtml|title=Ask.com Editorial Guidelines|accessdate=2007-04-18}}</ref><ref>{{cite web|url=http://www.google.com/webmasters/seo.html|title=Google's Guidelines on SEOs|accessdate=2007-04-18}}</ref><ref name="g-wmguide">{{cite web|url=http://www.google.com/webmasters/guidelines.html|title=Google's Guidelines on Site Design|accessdate=2007-04-18}}</ref><ref name="ms-wmguide">{{cite web|url=http://search.msn.com/docs/siteowner.aspx?t=SEARCH_WEBMASTER_REF_GuidelinesforOptimizingSite.htm|title=MSN Search Guidelines for successful indexing|accessdate=2007-04-18}}</ref><ref name="y-wmguide">{{cite web|url=http://help.yahoo.com/help/us/ysearch/deletions/deletions-05.html|title=Yahoo! Search Content Quality Guidelines|accessdate=2007-04-18}}</ref> are not written as a series of rules or commandments, this is an important distinction to note. White Hat SEO is not just about following guidelines, but is about ensuring that the content a search engine indexes and subsequently ranks is the same content a user will see.

White Hat advice is generally summed up as creating content for users, not for search engines, and then make that content easily accessible to their spiders, rather than game the system. White hat SEO is in many ways similar to web development that promotes accessibility,<ref>Andy Hagans, [[A List Apart]], [http://alistapart.com/articles/accessibilityseo High Accessibility Is Effective Search Engine Optimization]</ref> although the two are not identical.

===Spamdexing / "Black hat"===
{{main|Spamdexing}}

"Black hat" SEO are methods to try to improve rankings that are disapproved of by the search engines and/or involve deception. This can range from text that is "hidden", either as text colored similar to the background or in an invisible or left of visible div, or by redirecting users from a page that is built for search engines to one that is more human friendly. A method that sends a user to a page that was different from the page the search engined ranked is Black hat as a rule. One well known example is [[Cloaking]], the practice of serving one version of a page to search engine spiders/bots and another version to human visitors.

Search engines may penalize sites they discover using black hat methods, either by reducing their rankings or eliminating their listings from their databases altogether. Such penalties can be applied either automatically by the search engines' algorithms or by a manual review of a site.

One infamous example was the February 2006 Google removal of both [[BMW]] Germany and [[Ricoh]] Germany for use of deceptive practices.<ref name="intwebspam">[http://www.mattcutts.com/blog/ramping-up-on-international-webspam/ Ramping up on international webspam] by Matt Cutts, published February 4, 2006, at [http://www.mattcutts.com/blog Matt Cutts Blog]</ref> Both companies, however, quickly apologized, fixed the offending pages, and were restored to Google's list. [http://www.mattcutts.com/blog/recent-reinclusions/#comment-13170] [http://www.mattcutts.com/blog/recent-reinclusions/#comment-13181]

==SEO and marketing==
There is a considerable sized body of practitioners of SEO who see search engines as just another visitor to a site, and try to make the site as accessible to those visitors as to any other who would come to the pages. They often see the white hat/black hat dichotomy mentioned above as a [[false dilemma]]. The focus of their work is not primarily to rank the highest for certain terms in search engines, but rather to help site owners fulfill the business objectives of their sites. Indeed, ranking well for a few terms among the many possibilities does not guarantee more sales. A successful Internet marketing campaign may drive organic search results to pages, but it also may involve the use of paid advertising on search engines and other pages, building high quality web pages to engage and persuade, addressing technical issues that may keep search engines from crawling and indexing those sites, setting up analytics programs to enable site owners to measure their successes, and making sites accessible and usable.

SEO, as a marketing strategy, can often generate a good return. However, as the search engines are not paid for the traffic they send from organic search, the algorithms used can and do change, there are no guarantees of success, either in the short or long term. Due to this lack of guarantees and certainty, SEO is often compared to traditional Public Relations (PR), with [[Pay per click|PPC]] advertising closer to traditional advertising. Increased visitors is analogous to increased [[foot traffic]] in [[retail|retail advertising]]. Increased traffic may be detrimental to success if the site is not prepared to handle the traffic or visitors are generally dissatisfied with what they find. In either case increased traffic does not guarantee increased sales or success.

==Legal precedents==
In 2002, SearchKing filed suit in an [[Oklahoma]] court against the search engine [[Google]]. SearchKing's claim was that Google's tactics to prevent [[spamdexing]] constituted an unfair business practice. This may be compared to lawsuits that email spammers have filed against spam-fighters, as in various cases against MAPS and other [[DNSBL]]s. In January 2003, the court pronounced a [[summary judgment]] in Google's favor.<ref name="SearchKingLegal">[http://research.yale.edu/lawmeme/modules.php?name=News&file=article&sid=807] Google replies to SearchKing lawsuit, James Grimmelmann at LawMeme (research.yale.edu), January 09. 2006</ref> 

In March 2006, KinderStart.com, LLC filed a first amendment complaint against Google and also attempted to include potential members of the class of plaintiffs in a class action.<ref name="KinderStartLegal">[http://www.glawinfo.com/download/KSC_Complaint_1stAmd_Filed.pdf] (PDF) KinderStart.com, LLC, et al v. Google, Inc., C 06-2057 RS, filed March 17, 2006 in the Northern District of California, San Jose Division.</ref> The plaintiff's web site was removed from Google's index prior to the lawsuit and the amount of traffic to the site plummeted. On March 16, 2007 the [[United States District Court]] dismissed KinderStart's complaint without leave to amend, and partially granted Google's motion for [[Rule 11]] sanctions against KinderStart's attorney, Gregory John Yu, requiring him to pay part of Google's legal expenses.<ref>[http://claranet.scu.edu/tempfiles/tmp31509/kinderstartdismissal.pdf Order Graning Motion to Dismiss...], KinderStart.com LLC v. Google, Inc., C 06-2057 JF (N.D. Cal. March 16, 2007)</ref><ref>[http://claranet.scu.edu/tempfiles/tmp31510/kinderstartsanctions.pdf Order Granting in Part and Denying in Part Motion for Sanctions...], KinderStart.com LLC v. Google, Inc., C 06-2057 JF (N.D. Cal. March 16, 2007)</ref>

==References==
<!-- This is not the place to add your clever linkspam-->
<!-- Please post an explanation to the Talk Page before adding links here. -->
<!--<nowiki>
See http://en.wikipedia.org/wiki/Wikipedia:Footnotes for an explanation of how to generate footnotes using the<ref> and </ref> tags, and the template below.
</nowiki>-->
{{reflist|2}}

<!-- This is not the place to add your clever linkspam-->
<!-- Please post an explanation to the Talk Page before adding or changing links here. -->

==See also==
* [[Internet marketing]]
* [[Search engine marketing]]
* [[Social media optimization]]
* [[Spamdexing]]
* [[Wikipedia:Search engine optimization]]

;SEO Organizations
* [[Organization of Search Engine Optimization Professionals]]
* [[Search Engine Marketing Professional Organization]] (SEMPO)

;Notable SEOs
*See: [[:Category:Search engine optimization consultants]]

;Search Engine Representatives
* [[Matt Cutts]]
* [[Vanessa Fox]]
* [[Jeremy Zawodny]]
* [[Dan Crow]]
<!-- this list should become a category-->

<!-- ==============================({{NoMoreLinks}})============================== -->
<!-- DO NOT ADD LINKS TO THIS ARTICLE. WIKIPEDIA IS NOT A COLLECTION OF LINKS -->
<!-- If you think that your link might be useful, instead of placing it here, put -->
<!-- it on this article's discussion page first. Links that have not been verified -->
<!-- WILL BE DELETED -->
<!-- ============================================================================= -->

[[Category:Internet terminology]]
[[Category:Search engine optimization]]
[[Category:Marketing]]

[[ar:استمثال محركات البحث]]
[[bg:Оптимизация за търсачки]]
[[cs:Search Engine Optimization]]
[[da:Søgemaskineoptimering]]
[[de:Suchmaschinenoptimierung]]
[[et:Otsingumootori optimeerimine]]
[[es:Posicionamiento en buscadores]]
[[fa:بهینه سازی موتورهای جستجو]]
[[fr:Optimisation pour les moteurs de recherche]]
[[it:Ottimizzazione (motori di ricerca)]]
[[lt:SEO]]
[[nl:Zoekmachine-optimalisatie]]
[[ja:検索エンジン最適化]]
[[no:Søkemotoroptimalisering]]
[[pl:Pozycjonowanie stron]]
[[pt:Otimização para Sistemas de Busca SEO]]
[[ro:SEO]]
[[ru:Поисковая оптимизация]]
[[fi:Hakukoneoptimointi]]
[[sv:Sökmotoroptimering]]
[[th:Search Engine Optimization]]
[[zh:搜尋引擎最佳化]]